# Local Infrastructure Configuration (100% Local - No API Keys Required)

# ===== Vector Store Backend =====
# "faiss" (default): Requires TEI server for embeddings
# "qdrant": Mac Silicon compatible, no external server needed
# VECTOR_BACKEND=qdrant

# ===== FAISS Backend Settings (default) =====
# TEI Server (Text Embeddings Inference)
TEI_URL=http://localhost:8080

# ===== Qdrant Backend Settings (Mac Silicon) =====
# Uses in-memory Qdrant by default (no setup needed)
# Local SentenceTransformers embeddings (runs on CPU)
# EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
# COLLECTION_NAME=bitcoin_docs
# For production, use Qdrant Cloud:
# QDRANT_URL=https://your-cluster.qdrant.io
# QDRANT_API_KEY=your-api-key

# ===== LLM Configuration =====
# Claudex Server (Claude CLI Wrapper)
# https://github.com/Leeaandrob/claudex
CLAUDEX_URL=http://localhost:8081/v1

# Ollama (Fallback LLM)
OLLAMA_MODEL=qwen2.5:3b

# Use Claudex by default (set to false for Ollama)
USE_CLAUDEX=true

# Optional: OpenAI API Key (only if using OpenAI embeddings/models)
# OPENAI_API_KEY=sk-your-openai-api-key-here
